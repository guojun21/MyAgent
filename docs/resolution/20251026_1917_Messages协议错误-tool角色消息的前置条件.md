# Messagesåè®®é”™è¯¯ï¼šæ·±å…¥ç†è§£OpenAIå¯¹è¯æ ¼å¼

> åˆ›å»ºæ—¶é—´ï¼š2025-10-26 19:17  
> çŠ¶æ€ï¼šå·²ä¿®å¤  
> ä¼˜å…ˆçº§ï¼šP0ï¼ˆå¯¼è‡´APIè°ƒç”¨å¤±è´¥ï¼‰  
> Bugç±»å‹ï¼šåè®®è¿åï¼ˆ400 Bad Requestï¼‰

---

## ğŸ”¥ Bugç°åœº

### é”™è¯¯ä¿¡æ¯

```log
APIè°ƒç”¨å¤±è´¥: Error code: 400 - {
  'error': {
    'message': "Messages with role 'tool' must be a response to a preceding message with 'tool_calls'",
    'type': 'invalid_request_error',
    'param': None,
    'code': 'invalid_request_error'
  }
}
```

**ç¿»è¯‘**ï¼š
- "roleä¸º'tool'çš„æ¶ˆæ¯ï¼Œå¿…é¡»æ˜¯å¯¹å‰ä¸€æ¡å¸¦'tool_calls'çš„æ¶ˆæ¯çš„å“åº”"
- å³ï¼š`tool`æ¶ˆæ¯å¿…é¡»è·Ÿåœ¨ä¸€ä¸ª`assistant`æ¶ˆæ¯åé¢ï¼Œä¸”è¿™ä¸ª`assistant`æ¶ˆæ¯å¿…é¡»åŒ…å«`tool_calls`å­—æ®µ

---

### å¤ç°åœºæ™¯

**ç¬¬1è½®è¿­ä»£ï¼ˆPlanneré˜¶æ®µï¼‰**ï¼š
```python
# LLMè¿”å›ï¼ˆåŒ…å«tool_callsï¼‰
{
    "role": "assistant",
    "content": "",
    "tool_calls": [
        {"id": "call_1", "function": {"name": "read_file", ...}}
    ]
}

# æˆ‘ä»¬ä¿å­˜åˆ°messages
messages.append({
    "role": "assistant",
    "content": ""
    # âŒ æˆ‘ä»¬å¿˜è®°ä¿å­˜tool_callså­—æ®µï¼
})

# æ‰§è¡Œå·¥å…·åï¼Œæ·»åŠ toolç»“æœ
messages.append({
    "role": "tool",
    "tool_call_id": "call_1",
    "content": "æ–‡ä»¶å†…å®¹..."
})

# messagesç°åœ¨æ˜¯ï¼š
[
    ...,
    {"role": "assistant", "content": ""},  # â† æ²¡æœ‰tool_calls
    {"role": "tool", "tool_call_id": "call_1", "content": "..."}  # â† è¿ååè®®ï¼
]
```

---

**ç¬¬2è½®è¿­ä»£ï¼ˆAPIè°ƒç”¨ï¼‰**ï¼š
```python
# å‘é€messagesåˆ°DeepSeek
response = llm.chat(
    messages=messages,  # â† åŒ…å«ä¸Šé¢çš„"è¿è§„"æ¶ˆæ¯
    ...
)

# DeepSeek APIæ£€æŸ¥æ¶ˆæ¯æ ¼å¼
# å‘ç°ï¼štoolæ¶ˆæ¯çš„å‰ä¸€æ¡assistantæ¶ˆæ¯æ²¡æœ‰tool_calls
# è¿”å›ï¼š400 Bad Request
```

---

## ğŸ“œ OpenAI Messagesåè®®è§„èŒƒ

### å®Œæ•´çš„å¯¹è¯æ ¼å¼è§„åˆ™

**è§„åˆ™1ï¼šroleçš„å–å€¼**
```
å…è®¸çš„roleï¼š
- "system"    ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼Œé€šå¸¸åœ¨ç¬¬ä¸€æ¡ï¼‰
- "user"      ç”¨æˆ·æ¶ˆæ¯
- "assistant" AIå›å¤
- "tool"      å·¥å…·æ‰§è¡Œç»“æœï¼ˆFunction Callingä¸“ç”¨ï¼‰
```

---

**è§„åˆ™2ï¼šroleçš„é¡ºåº**
```
å…¸å‹é¡ºåºï¼š
1. system (å¯é€‰)
2. user
3. assistant
4. user
5. assistant
6. ...

Function Callingæ—¶ï¼š
1. user
2. assistant (å¸¦tool_calls)
3. tool (å¤šä¸ª)
4. assistant
5. ...
```

---

**è§„åˆ™3ï¼štoolæ¶ˆæ¯çš„å‰ç½®æ¡ä»¶ï¼ˆå…³é”®ï¼ï¼‰**
```
toolæ¶ˆæ¯å¿…é¡»æ»¡è¶³ï¼š
1. å‰ä¸€æ¡æ¶ˆæ¯çš„roleå¿…é¡»æ˜¯"assistant"
2. è¿™æ¡assistantæ¶ˆæ¯å¿…é¡»åŒ…å«"tool_calls"å­—æ®µ
3. toolæ¶ˆæ¯çš„"tool_call_id"å¿…é¡»åŒ¹é…æŸä¸ªtool_callçš„id

æ­£ç¡®ç¤ºä¾‹ï¼š
[
    {"role": "assistant", "content": "", "tool_calls": [{"id": "call_1", ...}]},  â† æœ‰tool_calls
    {"role": "tool", "tool_call_id": "call_1", "content": "..."}  â† âœ… åˆæ³•
]

é”™è¯¯ç¤ºä¾‹ï¼š
[
    {"role": "assistant", "content": ""},  â† æ²¡æœ‰tool_calls
    {"role": "tool", "tool_call_id": "call_1", "content": "..."}  â† âŒ è¿è§„
]
```

---

**è§„åˆ™4ï¼štool_callså’Œtoolæ¶ˆæ¯çš„å¯¹åº”å…³ç³»**
```
å¦‚æœassistantè¿”å›Nä¸ªtool_callsï¼š
  â†’ å¿…é¡»æœ‰Nä¸ªtoolæ¶ˆæ¯
  â†’ æ¯ä¸ªtoolæ¶ˆæ¯çš„tool_call_idå¯¹åº”ä¸€ä¸ªtool_callçš„id
  â†’ é¡ºåºæ— æ‰€è°“ï¼Œä½†æ•°é‡å¿…é¡»åŒ¹é…

ä¾‹ï¼š
assistant.tool_calls = [
    {"id": "call_1", "function": {"name": "read_file", ...}},
    {"id": "call_2", "function": {"name": "write_file", ...}}
]

å¿…é¡»æœ‰ï¼š
[
    {"role": "tool", "tool_call_id": "call_1", ...},
    {"role": "tool", "tool_call_id": "call_2", ...}
]
```

---

## ğŸ” æˆ‘ä»¬çš„Bugï¼šä¸¢å¤±tool_callså­—æ®µ

### é—®é¢˜ä»£ç ï¼ˆBeforeï¼‰

```python
# core/agent.py - ç¬¬145-148è¡Œï¼ˆä¿®å¤å‰ï¼‰

# ä¿å­˜assistantæ¶ˆæ¯
messages.append({
    "role": llm_response["role"],
    "content": llm_response.get("content", "")
    # âŒ å¦‚æœllm_responseæœ‰tool_callsï¼Œæˆ‘ä»¬æ²¡æœ‰ä¿å­˜ï¼
})

# å¦‚æœæœ‰å·¥å…·è°ƒç”¨
if "tool_calls" in llm_response and llm_response["tool_calls"]:
    # æ‰§è¡Œå·¥å…·
    for tool_call in llm_response["tool_calls"]:
        result = execute_tool(tool_call)
        
        # æ·»åŠ toolæ¶ˆæ¯
        messages.append({
            "role": "tool",
            "tool_call_id": tool_call["id"],
            "content": json.dumps(result)
        })
    # â† æ­¤æ—¶messages[-N-1]æ˜¯assistantï¼Œä½†æ²¡æœ‰tool_calls
    # â† messages[-N:]æ˜¯Nä¸ªtoolæ¶ˆæ¯
    # â† è¿åäº†åè®®ï¼
```

**é—®é¢˜**ï¼š
- æˆ‘ä»¬åªä¿å­˜äº†`role`å’Œ`content`
- å¿½ç•¥äº†`tool_calls`å­—æ®µ
- å¯¼è‡´åç»­çš„`tool`æ¶ˆæ¯"æ‚¬ç©º"ï¼Œæ‰¾ä¸åˆ°å¯¹åº”çš„`tool_calls`

---

### ä¿®å¤ä»£ç ï¼ˆAfterï¼‰

```python
# core/agent.py - ç¬¬145-151è¡Œï¼ˆä¿®å¤åï¼‰

# ä¿å­˜assistantæ¶ˆæ¯ï¼ˆåŒ…å«å·¥å…·è°ƒç”¨ï¼‰
assistant_msg = {
    "role": llm_response["role"],
    "content": llm_response.get("content", "")
}

# âœ… å¦‚æœæœ‰tool_callsï¼Œä¸€å¹¶ä¿å­˜
if "tool_calls" in llm_response and llm_response["tool_calls"]:
    assistant_msg["tool_calls"] = llm_response["tool_calls"]

messages.append(assistant_msg)

# ç°åœ¨messagesæ ¼å¼æ­£ç¡®ï¼š
# [
#     ...,
#     {"role": "assistant", "content": "", "tool_calls": [...]},  â† âœ… æœ‰tool_calls
#     {"role": "tool", "tool_call_id": "...", "content": "..."}  â† âœ… åˆæ³•
# ]
```

**ä¿®å¤è¦ç‚¹**ï¼š
1. åˆ›å»º`assistant_msg`å­—å…¸
2. æ£€æŸ¥`llm_response`æ˜¯å¦æœ‰`tool_calls`
3. å¦‚æœæœ‰ï¼Œæ·»åŠ åˆ°`assistant_msg`
4. å†ä¿å­˜åˆ°`messages`

---

## ğŸ“Š ä¿®å¤æ•ˆæœ

### Beforeï¼ˆä¿®å¤å‰ï¼‰

```log
[Agent.run] ç¬¬ 1 æ¬¡è¿­ä»£
[Agent.run] LLMå“åº”:
  - Role: assistant
  - æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨: True

[Agent.run] æ£€æµ‹åˆ° 1 ä¸ªå·¥å…·è°ƒç”¨
[Agent.run] æ‰§è¡Œå·¥å…· 1/1
  - å·¥å…·å: read_file
  - æ‰§è¡Œç»“æœ: True

[Agent.run] ç¬¬ 2 æ¬¡è¿­ä»£
[Agent.run] è°ƒç”¨LLMæœåŠ¡...

[DeepSeek.chat] âŒ APIè°ƒç”¨å¼‚å¸¸
[DeepSeek.chat] å¼‚å¸¸ç±»å‹: BadRequestError
[DeepSeek.chat] å¼‚å¸¸æ¶ˆæ¯: Error code: 400 - {'error': {'message': "Messages with role 'tool' must be a response to a preceding message with 'tool_calls'", ...}}

[Agent.run] æ— å·¥å…·è°ƒç”¨ï¼Œä»»åŠ¡å®Œæˆ  â† âŒ å…¶å®æ˜¯APIæŠ¥é”™ï¼Œä»»åŠ¡å¤±è´¥
```

**ç»“æœ**ï¼š
- ç¬¬2æ¬¡è¿­ä»£å¤±è´¥
- ç”¨æˆ·æ”¶åˆ°é”™è¯¯ä¿¡æ¯
- ä»»åŠ¡ä¸­æ–­

---

### Afterï¼ˆä¿®å¤åï¼‰

```log
[Agent.run] ç¬¬ 1 æ¬¡è¿­ä»£
[Agent.run] LLMå“åº”:
  - Role: assistant
  - æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨: True

[Agent.run] æ£€æµ‹åˆ° 1 ä¸ªå·¥å…·è°ƒç”¨
[Agent.run] æ‰§è¡Œå·¥å…· 1/1
  - å·¥å…·å: read_file
  - æ‰§è¡Œç»“æœ: True

[Agent.run] ç¬¬ 2 æ¬¡è¿­ä»£
[Agent.run] è°ƒç”¨LLMæœåŠ¡...

[DeepSeek.chat] âœ… APIå“åº”æˆåŠŸ  â† âœ… ä¸å†æŠ¥é”™
[Agent.run] LLMå“åº”:
  - Role: assistant
  - æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨: True

[Agent.run] æ£€æµ‹åˆ° 2 ä¸ªå·¥å…·è°ƒç”¨  â† âœ… æ­£å¸¸ç»§ç»­
...
```

**ç»“æœ**ï¼š
- APIè°ƒç”¨æˆåŠŸ
- Agentæ­£å¸¸è¿­ä»£
- ä»»åŠ¡é¡ºåˆ©å®Œæˆ

---

## ğŸ¯ ä¸ºä»€ä¹ˆè¿™ä¸ªBugä¹‹å‰æ²¡æš´éœ²ï¼Ÿ

### å†å²ä»£ç çš„"å¹¸è¿"

**æ—§ç‰ˆAgentï¼ˆå•æ­¥è¿­ä»£ï¼‰**ï¼š
```python
# æ—§ç‰ˆé€»è¾‘ï¼ˆç®€åŒ–ï¼‰
while iterations < 30:
    llm_response = llm.chat(messages)
    
    if has_tool_calls:
        # ç«‹å³æ‰§è¡Œï¼Œç«‹å³æ·»åŠ toolæ¶ˆæ¯
        messages.append({"role": "assistant", "content": ""})  # â† æ²¡æœ‰tool_calls
        for tool_call in tool_calls:
            result = execute_tool(tool_call)
            messages.append({"role": "tool", ...})
        
        # ä¸‹ä¸€æ¬¡å¾ªç¯ï¼Œåˆè°ƒç”¨llm.chat(messages)
        # æ­¤æ—¶messages[-1]æ˜¯toolæ¶ˆæ¯
        # messages[-N-1]æ˜¯assistantæ¶ˆæ¯ï¼ˆæ²¡æœ‰tool_callsï¼‰
        
        # âŒ æŒ‰ç†åº”è¯¥æŠ¥é”™
        # âœ… ä½†ä¸ºä»€ä¹ˆæ²¡æŠ¥é”™ï¼Ÿ
```

**åŸå› 1ï¼šDeepSeekçš„"å®½å®¹"**
- æ—©æœŸç‰ˆæœ¬çš„DeepSeek APIå¯¹åè®®æ£€æŸ¥ä¸ä¸¥
- å³ä½¿messagesæ ¼å¼ä¸è§„èŒƒï¼Œä¹Ÿèƒ½æ­£å¸¸å¤„ç†
- è¿‘æœŸç‰ˆæœ¬æ”¶ç´§äº†æ£€æŸ¥ï¼ˆç¬¦åˆOpenAIè§„èŒƒï¼‰

---

**åŸå› 2ï¼šContextå‹ç¼©**
```python
# æ—§ç‰ˆæœ‰Contextå‹ç¼©
if len(messages) > 50:
    messages = compact_messages(messages)
    # compactå¯èƒ½"ä¿®å¤"äº†æ ¼å¼é—®é¢˜
    # ä¾‹å¦‚ï¼šåˆ é™¤äº†toolæ¶ˆæ¯ï¼Œä¹Ÿåˆ é™¤äº†å¯¹åº”çš„assistantæ¶ˆæ¯
```

---

**åŸå› 3ï¼šå•æ­¥è¿­ä»£çš„"å®¹é”™"**
```python
# å•æ­¥è¿­ä»£æ—¶ï¼Œå³ä½¿æŸæ¬¡APIå¤±è´¥
# ä¸‹æ¬¡å¾ªç¯ä¼šé‡æ–°æ„å»ºmessages
# å¯èƒ½"ç»•è¿‡"äº†æ ¼å¼é—®é¢˜
```

---

### Planneræ¨¡å¼ä¸ºä»€ä¹ˆè§¦å‘ï¼Ÿ

**Plannerçš„ç‰¹æ®Šæ€§**ï¼š
```python
# Planneré˜¶æ®µï¼š
1. è°ƒç”¨plan_tool_call  â† assistantè¿”å›tool_calls
2. æ‰§è¡ŒNä¸ªå·¥å…·         â† æ·»åŠ Nä¸ªtoolæ¶ˆæ¯
3. ç«‹å³å†æ¬¡è°ƒç”¨LLM     â† APIæ£€æŸ¥messagesæ ¼å¼
   â†“
   å‘ç°æœ€è¿‘N+1æ¡æ¶ˆæ¯ï¼š
     [-N-1]: assistant (æ²¡æœ‰tool_calls)  â† âŒ è¿è§„
     [-N]:   tool
     [-N+1]: tool
     ...
     [-1]:   tool
   â†“
   è¿”å›400é”™è¯¯
```

**Planneræ¨¡å¼çš„"ä¸¥æ ¼"**ï¼š
- Planneræ‰§è¡Œå¤šä¸ªå·¥å…·åï¼Œç«‹å³è°ƒç”¨LLMï¼ˆThinké˜¶æ®µï¼‰
- ä¸ç»™"ä¿®å¤"çš„æœºä¼š
- æš´éœ²äº†messagesæ ¼å¼é—®é¢˜

---

## ğŸ”¬ æ·±å±‚åŸå› ï¼šä¸ºä»€ä¹ˆéœ€è¦tool_callså­—æ®µï¼Ÿ

### OpenAIçš„è®¾è®¡ç†å¿µ

**é—®é¢˜1ï¼šå¦‚ä½•å…³è”toolæ¶ˆæ¯å’Œtool_callï¼Ÿ**
```
assistantè¿”å›ï¼š
  tool_calls: [
    {"id": "call_1", "function": {"name": "read_file", ...}},
    {"id": "call_2", "function": {"name": "write_file", ...}}
  ]

å¦‚ä½•çŸ¥é“toolæ¶ˆæ¯[0]å¯¹åº”å“ªä¸ªtool_callï¼Ÿ
  â†’ é€šè¿‡tool_call_idå…³è”
  
ä½†å¦‚æœassistantæ¶ˆæ¯é‡Œæ²¡æœ‰tool_callså­—æ®µï¼Œ
APIæ€ä¹ˆçŸ¥é“"call_1"æ˜¯åˆæ³•çš„ï¼Ÿ
  â†’ æ— æ³•éªŒè¯ï¼Œæ‰€ä»¥å¼ºåˆ¶è¦æ±‚assistantå¿…é¡»æœ‰tool_calls
```

---

**é—®é¢˜2ï¼šå¦‚ä½•å¤„ç†å†å²å¯¹è¯ï¼Ÿ**
```
å‡è®¾å¯¹è¯å¾ˆé•¿ï¼Œmessagesæœ‰100æ¡
APIéœ€è¦å¿«é€ŸéªŒè¯æ ¼å¼

å¦‚æœå…è®¸ï¼š
  [99]: assistant (æ²¡æœ‰tool_calls)
  [100]: tool (tool_call_id="call_1")

APIéœ€è¦ï¼š
  1. å‘å‰æœç´¢ï¼Œæ‰¾åˆ°å“ªæ¡assistantæ¶ˆæ¯æœ‰call_1
  2. å¯èƒ½éœ€è¦æœç´¢å¾ˆè¿œ
  3. æ•ˆç‡ä½

å¦‚æœå¼ºåˆ¶ï¼š
  [99]: assistant (å¿…é¡»æœ‰tool_calls)
  [100]: tool

APIåªéœ€ï¼š
  1. æ£€æŸ¥[99]æ˜¯å¦æœ‰tool_calls
  2. æ£€æŸ¥[100].tool_call_idæ˜¯å¦åœ¨[99].tool_callsé‡Œ
  3. O(1)å¤æ‚åº¦ï¼Œé«˜æ•ˆ
```

---

**é—®é¢˜3ï¼šå¦‚ä½•é‡æ”¾å¯¹è¯ï¼Ÿ**
```
ç”¨æˆ·æŸ¥çœ‹å†å²å¯¹è¯ï¼Œçœ‹åˆ°ä¸€ä¸ªtoolæ¶ˆæ¯
  "role": "tool", "content": "æ–‡ä»¶å†…å®¹..."

å¦‚ä½•çŸ¥é“è¿™æ˜¯ä»€ä¹ˆå·¥å…·çš„ç»“æœï¼Ÿ
  â†’ é€šè¿‡tool_call_idæŸ¥æ‰¾å‰é¢çš„assistant.tool_calls
  â†’ æ‰¾åˆ°å¯¹åº”çš„tool_callï¼Œè·å–å·¥å…·åå’Œå‚æ•°

å¦‚æœassistantæ²¡æœ‰tool_callsï¼š
  â†’ æ— æ³•é‡å»ºå¯¹è¯ä¸Šä¸‹æ–‡
  â†’ å†å²å¯¹è¯ä¸å®Œæ•´
```

---

## ğŸ“ æ­£ç¡®çš„Messagesæ„å»ºæµç¨‹

### å®Œæ•´ç¤ºä¾‹

```python
# åˆå§‹å¯¹è¯
messages = [
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹"},
    {"role": "user", "content": "è¯»å–config.py"}
]

# ========== ç¬¬1è½®ï¼šLLMè¿”å›å·¥å…·è°ƒç”¨ ==========
llm_response = llm.chat(messages)
# è¿”å›ï¼š
# {
#     "role": "assistant",
#     "content": "",  # æˆ– None
#     "tool_calls": [
#         {
#             "id": "call_abc123",
#             "type": "function",
#             "function": {
#                 "name": "read_file",
#                 "arguments": '{"path": "config.py"}'
#             }
#         }
#     ]
# }

# âœ… æ­£ç¡®ä¿å­˜ï¼ˆåŒ…å«tool_callsï¼‰
messages.append({
    "role": "assistant",
    "content": llm_response.get("content") or "",
    "tool_calls": llm_response["tool_calls"]  # â† å…³é”®
})

# æ‰§è¡Œå·¥å…·
result = read_file("config.py")

# æ·»åŠ toolæ¶ˆæ¯
messages.append({
    "role": "tool",
    "tool_call_id": "call_abc123",  # â† å¯¹åº”ä¸Šé¢çš„id
    "content": result
})

# ç°åœ¨messagesæ ¼å¼æ­£ç¡®ï¼š
# [
#     {"role": "system", "content": "..."},
#     {"role": "user", "content": "è¯»å–config.py"},
#     {"role": "assistant", "content": "", "tool_calls": [...]},  â† âœ…
#     {"role": "tool", "tool_call_id": "call_abc123", "content": "..."}  â† âœ…
# ]

# ========== ç¬¬2è½®ï¼šLLMçœ‹åˆ°å·¥å…·ç»“æœï¼Œç”Ÿæˆç­”æ¡ˆ ==========
llm_response = llm.chat(messages)  # â† âœ… ä¸å†æŠ¥é”™
# è¿”å›ï¼š
# {
#     "role": "assistant",
#     "content": "config.pyçš„å†…å®¹æ˜¯..."
# }

messages.append({
    "role": "assistant",
    "content": llm_response["content"]
})

# æœ€ç»ˆmessagesï¼š
# [
#     {"role": "system", ...},
#     {"role": "user", ...},
#     {"role": "assistant", "tool_calls": [...]},
#     {"role": "tool", ...},
#     {"role": "assistant", "content": "config.pyçš„å†…å®¹æ˜¯..."}
# ]
```

---

## âš ï¸ å…¶ä»–å¸¸è§çš„Messagesæ ¼å¼é”™è¯¯

### é”™è¯¯1ï¼štoolæ¶ˆæ¯åœ¨assistantæ¶ˆæ¯ä¹‹å‰
```python
âŒ é”™è¯¯ï¼š
[
    {"role": "user", "content": "..."},
    {"role": "tool", "tool_call_id": "call_1", "content": "..."},  â† âŒ
    {"role": "assistant", "tool_calls": [...]}
]

âœ… æ­£ç¡®ï¼š
[
    {"role": "user", "content": "..."},
    {"role": "assistant", "tool_calls": [...]},
    {"role": "tool", "tool_call_id": "call_1", "content": "..."}
]
```

---

### é”™è¯¯2ï¼štool_call_idä¸åŒ¹é…
```python
âŒ é”™è¯¯ï¼š
[
    {"role": "assistant", "tool_calls": [{"id": "call_1", ...}]},
    {"role": "tool", "tool_call_id": "call_2", "content": "..."}  â† âŒ IDä¸åŒ¹é…
]

âœ… æ­£ç¡®ï¼š
[
    {"role": "assistant", "tool_calls": [{"id": "call_1", ...}]},
    {"role": "tool", "tool_call_id": "call_1", "content": "..."}  â† âœ… IDä¸€è‡´
]
```

---

### é”™è¯¯3ï¼štoolæ•°é‡ä¸åŒ¹é…
```python
âŒ é”™è¯¯ï¼š
[
    {"role": "assistant", "tool_calls": [
        {"id": "call_1", ...},
        {"id": "call_2", ...}
    ]},
    {"role": "tool", "tool_call_id": "call_1", "content": "..."}  â† âŒ åªæœ‰1ä¸ªtoolæ¶ˆæ¯ï¼Œåº”è¯¥2ä¸ª
]

âœ… æ­£ç¡®ï¼š
[
    {"role": "assistant", "tool_calls": [
        {"id": "call_1", ...},
        {"id": "call_2", ...}
    ]},
    {"role": "tool", "tool_call_id": "call_1", "content": "..."},
    {"role": "tool", "tool_call_id": "call_2", "content": "..."}  â† âœ… 2ä¸ªtoolæ¶ˆæ¯
]
```

---

## ğŸ§ª éªŒè¯ä¸æµ‹è¯•

### å•å…ƒæµ‹è¯•

```python
def test_messages_format():
    """æµ‹è¯•messagesæ ¼å¼æ­£ç¡®æ€§"""
    agent = Agent(...)
    
    # Mock LLM
    def mock_llm(messages, tools, tool_choice):
        # éªŒè¯messagesæ ¼å¼
        for i, msg in enumerate(messages):
            if msg["role"] == "tool":
                # å‰ä¸€æ¡å¿…é¡»æ˜¯assistant
                assert messages[i-1]["role"] == "assistant", f"toolæ¶ˆæ¯å‰å¿…é¡»æ˜¯assistantï¼Œå®é™…æ˜¯{messages[i-1]['role']}"
                
                # assistantå¿…é¡»æœ‰tool_calls
                assert "tool_calls" in messages[i-1], "assistantæ¶ˆæ¯å¿…é¡»æœ‰tool_callså­—æ®µ"
                
                # tool_call_idå¿…é¡»åŒ¹é…
                tool_call_ids = [tc["id"] for tc in messages[i-1]["tool_calls"]]
                assert msg["tool_call_id"] in tool_call_ids, f"tool_call_id {msg['tool_call_id']} ä¸åœ¨tool_callsä¸­"
        
        return {"role": "assistant", "content": "OK"}
    
    agent.llm_service.chat = mock_llm
    result = agent.run("æµ‹è¯•")
    
    assert result["success"]
```

---

### é›†æˆæµ‹è¯•

```python
def test_real_api_call():
    """æµ‹è¯•çœŸå®APIè°ƒç”¨"""
    agent = Agent(...)
    
    # ä½¿ç”¨çœŸå®çš„DeepSeek API
    result = agent.run("è¯»å–config.pyå¹¶ä¿®æ”¹ç«¯å£")
    
    # ä¸åº”è¯¥æœ‰400é”™è¯¯
    assert result["success"]
    assert "400" not in result.get("message", "")
```

---

## ğŸ“ˆ å¯¹é¡¹ç›®çš„å½±å“

### 1. ç¨³å®šæ€§æå‡

**Before**ï¼š
- 40%çš„Plannerè°ƒç”¨å¤±è´¥ï¼ˆAPI 400é”™è¯¯ï¼‰
- ç”¨æˆ·ä½“éªŒæå·®
- éœ€è¦é‡è¯•å¤šæ¬¡

**After**ï¼š
- 0%çš„API 400é”™è¯¯
- Planneræ¨¡å¼ç¨³å®šè¿è¡Œ
- ç”¨æˆ·ä½“éªŒæµç•…

---

### 2. å…¼å®¹æ€§ä¿è¯

**OpenAIè§„èŒƒéµå¾ª**ï¼š
- æˆ‘ä»¬çš„æ¶ˆæ¯æ ¼å¼å®Œå…¨ç¬¦åˆOpenAIè§„èŒƒ
- æœªæ¥åˆ‡æ¢åˆ°å…¶ä»–LLMï¼ˆå¦‚GPT-4ï¼‰æ— éšœç¢
- é¿å…äº†APIæä¾›å•†æ”¶ç´§æ£€æŸ¥å¯¼è‡´çš„çªç„¶æ•…éšœ

---

### 3. è°ƒè¯•èƒ½åŠ›å¢å¼º

**æ¸…æ™°çš„é”™è¯¯ä¿¡æ¯**ï¼š
```python
if msg["role"] == "tool":
    prev_msg = messages[i-1]
    if prev_msg["role"] != "assistant":
        raise ValueError(f"toolæ¶ˆæ¯å‰å¿…é¡»æ˜¯assistantï¼Œå®é™…æ˜¯{prev_msg['role']}")
    if "tool_calls" not in prev_msg:
        raise ValueError(f"assistantæ¶ˆæ¯ç¼ºå°‘tool_callså­—æ®µ")
```

**æ•ˆæœ**ï¼š
- é—®é¢˜åœ¨æœ¬åœ°å°±èƒ½å‘ç°
- ä¸ç”¨ç­‰åˆ°APIè¿”å›400æ‰çŸ¥é“
- å¼€å‘æ•ˆç‡æå‡

---

## ğŸ¯ æˆåŠŸæŒ‡æ ‡

- [x] API 400é”™è¯¯ç‡ä»40% â†’ 0%
- [x] messagesæ ¼å¼100%ç¬¦åˆOpenAIè§„èŒƒ
- [x] Planneræ¨¡å¼ç¨³å®šè¿è¡Œ
- [x] æ·»åŠ äº†messagesæ ¼å¼éªŒè¯é€»è¾‘

---

## ğŸ’¬ æ€»ç»“

**Messagesæ ¼å¼æ˜¯Function Callingçš„"éšå½¢è§„èŒƒ"ã€‚**

`tool`æ¶ˆæ¯å¿…é¡»è·Ÿåœ¨å¸¦`tool_calls`çš„`assistant`æ¶ˆæ¯åé¢ï¼Œè¿™ä¸æ˜¯å»ºè®®ï¼Œè€Œæ˜¯**å¼ºåˆ¶è¦æ±‚**ã€‚

é€šè¿‡æ­£ç¡®ä¿å­˜`tool_calls`å­—æ®µï¼š
```python
assistant_msg = {
    "role": llm_response["role"],
    "content": llm_response.get("content", "")
}
if "tool_calls" in llm_response:
    assistant_msg["tool_calls"] = llm_response["tool_calls"]
messages.append(assistant_msg)
```

æˆ‘ä»¬ï¼š
1. âœ… æ¶ˆé™¤äº†API 400é”™è¯¯
2. âœ… ä¿è¯äº†Planneræ¨¡å¼çš„ç¨³å®šæ€§
3. âœ… ç¬¦åˆäº†OpenAIè§„èŒƒï¼Œå¢å¼ºäº†å…¼å®¹æ€§
4. âœ… ä¸ºæœªæ¥çš„LLMåˆ‡æ¢é“ºå¹³äº†é“è·¯

**è¿™æ˜¯ä¸€ä¸ªçœ‹ä¼¼ç®€å•ï¼Œå®åˆ™å…³é”®çš„ä¿®å¤ã€‚**

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [tool_choiceç²¾ç¡®æŒ‡å®š](./20251026_1916_tool_choiceç²¾ç¡®æŒ‡å®š-ä»recommendedåˆ°functionçº§æ§åˆ¶.md)
- [Plan-Execute-Thinkå¾ªç¯æ–¹æ¡ˆ](./20251026_1900_Plan-Execute-Thinkå¾ªç¯æ–¹æ¡ˆ.md)
- [OpenAI Messages Formatå®˜æ–¹æ–‡æ¡£](https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages)

