"""
APIæ—¥å¿—åˆ†æžå·¥å…·
ç”¨äºŽç»Ÿè®¡å’Œåˆ†æžAPIè°ƒç”¨æ—¥å¿—
"""
import json
from pathlib import Path
from collections import defaultdict
from datetime import datetime
import sys
import io

# è®¾ç½®è¾“å‡ºç¼–ç ä¸ºUTF-8
if sys.stdout.encoding != 'utf-8':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')


class APILogAnalyzer:
    """APIæ—¥å¿—åˆ†æžå™¨"""
    
    def __init__(self, log_root: str = "llmlogs/apiCall"):
        self.log_root = Path(log_root)
    
    def analyze_date(self, date: str = None):
        """åˆ†æžæŸå¤©çš„APIè°ƒç”¨"""
        
        if date is None:
            date = datetime.now().strftime('%Y%m%d')
        
        date_dir = self.log_root / date
        
        if not date_dir.exists():
            print(f"âŒ æ²¡æœ‰{date}çš„æ—¥å¿—")
            return
        
        stats = {
            "total_calls": 0,
            "total_tokens": 0,
            "total_cost": 0.0,
            "by_session": defaultdict(lambda: {"calls": 0, "tokens": 0, "cost": 0.0}),
            "by_tool": defaultdict(int),
            "by_finish_reason": defaultdict(int),
            "avg_latency": 0,
            "max_latency": 0
        }
        
        latencies = []
        
        # éåŽ†æ‰€æœ‰call
        for call_dir in date_dir.rglob("call_*"):
            if not call_dir.is_dir():
                continue
            
            metadata_file = call_dir / "metadata.json"
            if not metadata_file.exists():
                continue
            
            try:
                metadata = json.loads(metadata_file.read_text(encoding='utf-8'))
            except:
                print(f"âš ï¸ æ— æ³•è§£æž: {metadata_file}")
                continue
            
            # ç»Ÿè®¡
            stats["total_calls"] += 1
            stats["total_tokens"] += metadata["usage"].get("total_tokens", 0)
            stats["total_cost"] += metadata["cost_estimate"]["total_cost"]
            
            session = metadata["session_id"]
            stats["by_session"][session]["calls"] += 1
            stats["by_session"][session]["tokens"] += metadata["usage"].get("total_tokens", 0)
            stats["by_session"][session]["cost"] += metadata["cost_estimate"]["total_cost"]
            
            stats["by_finish_reason"][metadata["response_info"]["finish_reason"]] += 1
            
            latencies.append(metadata["performance"]["latency_ms"])
            
            # å·¥å…·è°ƒç”¨ç»Ÿè®¡
            output_file = call_dir / "output.json"
            if output_file.exists():
                try:
                    output = json.loads(output_file.read_text(encoding='utf-8'))
                    choices = output.get("choices", [])
                    if choices:
                        tool_calls = choices[0].get("message", {}).get("tool_calls", [])
                        for tc in tool_calls:
                            tool_name = tc["function"]["name"]
                            stats["by_tool"][tool_name] += 1
                except:
                    pass
        
        # è®¡ç®—å¹³å‡å€¼
        if latencies:
            stats["avg_latency"] = sum(latencies) / len(latencies)
            stats["max_latency"] = max(latencies)
        
        # æ‰“å°æŠ¥å‘Š
        self._print_report(date, stats)
        
        return stats
    
    def _print_report(self, date: str, stats: dict):
        """æ‰“å°åˆ†æžæŠ¥å‘Š"""
        
        print(f"\n{'='*80}")
        print(f"APIè°ƒç”¨åˆ†æžæŠ¥å‘Š - {date}")
        print(f"{'='*80}\n")
        
        print(f"ðŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"  æ€»è°ƒç”¨æ¬¡æ•°: {stats['total_calls']}")
        print(f"  æ€»Tokenæ¶ˆè€—: {stats['total_tokens']:,}")
        print(f"  æ€»æˆæœ¬: Â¥{stats['total_cost']:.4f}")
        print(f"  å¹³å‡å»¶è¿Ÿ: {stats['avg_latency']:.0f}ms")
        print(f"  æœ€å¤§å»¶è¿Ÿ: {stats['max_latency']:.0f}ms")
        print("")
        
        print(f"ðŸ”§ å·¥å…·è°ƒç”¨ç»Ÿè®¡:")
        if stats["by_tool"]:
            for tool, count in sorted(stats["by_tool"].items(), key=lambda x: x[1], reverse=True):
                print(f"  {tool}: {count}æ¬¡")
        else:
            print(f"  (æ²¡æœ‰å·¥å…·è°ƒç”¨)")
        print("")
        
        print(f"ðŸ“ ç»“æŸåŽŸå› :")
        for reason, count in stats["by_finish_reason"].items():
            print(f"  {reason}: {count}æ¬¡")
        print("")
        
        print(f"ðŸ’¬ æŒ‰Sessionç»Ÿè®¡:")
        sessions = list(stats["by_session"].items())[:5]
        if sessions:
            for session, data in sessions:
                if session is None:
                    session_display = "unknown"
                elif len(session) > 8:
                    session_display = session[:8] + "..."
                else:
                    session_display = session
                print(f"  {session_display}")
                print(f"    è°ƒç”¨: {data['calls']}æ¬¡")
                print(f"    Token: {data['tokens']:,}")
                print(f"    æˆæœ¬: Â¥{data['cost']:.4f}")
        else:
            print(f"  (æ²¡æœ‰Session)")
        
        print(f"\n{'='*80}\n")


def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    analyzer = APILogAnalyzer()
    
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        date = sys.argv[1]
    else:
        date = None
    
    analyzer.analyze_date(date)


if __name__ == "__main__":
    main()

